<!DOCTYPE html>
<html lang="en-US">

<head>
  <script src="face-api.js"></script>
  <script src="js/drawing.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <div class="margin">
    <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
    <canvas id="overlay"></canvas>
    <div id='popup'>
      <h2 id='message'></h2>
      <button id='open' onclick="saveLogin()">Open the Door!</button>
      <button id='cancel' onclick="cancel()">Cancel</button>
    </div>
  </div>
</body>
  <script type="text/javascript">

    async function onPlay() {
      // run face detection & recognition
      const videoEl = $('#inputVideo').get(0)
      if(videoEl.paused || videoEl.ended){
        return setTimeout(() => onPlay());
      }

      // configure SSD detection parameters
      // const options = new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 })
      // configure tiny face detectir
      const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 128})

      // compute reference image
      const labels = ['Haoqing', 'Rui'];

      const labeledFaceDescriptors = await Promise.all(
        labels.map(async label => {
          // fetch image data from urls and convert blob to HTMLImage element
          const imgUrl = `img/${label}.jpg`

          const img = await faceapi.fetchImage(imgUrl)
          /*
          var img;
          var json = $.getJSON("img_data.json",function(jsondata) {
            img = faceapi.bufferToImage("data:image/jpg;base64,".concat(jsondata[label]))
            console.log(img)
            console.log(typeof(img))
          });

          console.log(img)
          */
          // detect the face with the highest score in the image and compute it's landmarks and face descriptor
          const fullFaceDescription = await faceapi.detectSingleFace(img, options).withFaceLandmarks().withFaceDescriptor()
          
          if (!fullFaceDescription) {
            throw new Error(`no faces detected for ${label}`)
          }
          
          const faceDescriptors = [fullFaceDescription.descriptor]
          return new faceapi.LabeledFaceDescriptors(label, faceDescriptors)
        })
      )

      // 0.6 is a good distance threshold value to judge
      // whether the descriptors match or not
      // create FaceMatcher with automatically assigned labels
      // from the detection results for the reference image
      const maxDescriptorDistance = 0.6;
      const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, maxDescriptorDistance);
      updateResults(faceMatcher,options);

    }
  	  
    async function run() {
      // load the models
      const MODEL_URL = 'weights';
      // SSDMobileNet
      //await faceapi.loadSsdMobilenetv1Model(MODEL_URL) 
      //await faceapi.loadFaceLandmarkModel(MODEL_URL)

      // tiny face detector
      await faceapi.loadTinyFaceDetectorModel(MODEL_URL);
      await faceapi.loadFaceLandmarkModel(MODEL_URL)
      await faceapi.loadFaceRecognitionModel(MODEL_URL)

      // try to access users webcam and stream the images
      // to the video element
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
      const videoEl = $('#inputVideo').get(0);
      videoEl.srcObject = stream;

      
    }

    async function updateResults(faceMatcher, options, lastPerson) {

      const videoEl = $('#inputVideo').get(0);
      const canvas = $('#overlay').get(0);

      // single face detection
      const results = await faceapi.detectSingleFace(videoEl, options).withFaceLandmarks().withFaceDescriptor();

      // all faces detection
      // const results = await faceapi.detectAllFaces(videoEl, options).withFaceLandmarks().withFaceDescriptors()
      if (results) {
        const bestMatch = faceMatcher.findBestMatch(results.descriptor);
        var name =  bestMatch._label;
        

        if (name != 'unknown' && name != lastPerson){
          
          $('#message').text("Welcome Back! " + name );
          $('#popup').show();

          // draw box on convas

          
          resizedResults = resizeCanvasAndResults(videoEl, canvas, [results]);

          // draw boxes with the corresponding label as text
          const boxesWithText = resizedResults.map(({ detection, descriptor }) =>
            new faceapi.BoxWithText(
              detection.box,
              // match each face descriptor to the reference descriptor
              // with lowest euclidean distance and display the result as text
              //faceMatcher.findBestMatch(descriptor).toString()
            )
          );
          faceapi.drawDetection(canvas, boxesWithText);

          // hide poppu message in 3 seconds
          setTimeout(() => $('#popup').hide( ), 3000);
          setTimeout(() => canvas.width = canvas.width, 3000)
          
        }
      }
      setTimeout(() => updateResults(faceMatcher, options, name), 2000);
    }

    function saveLogin() {
      var API_URL = 'https://uncxy3iqd1.execute-api.us-east-1.amazonaws.com/prod/doorkey'
      $.ajax({
        type: 'POST',
        url: API_URL,
        headers: {  'Access-Control-Allow-Headers': 'Content-Type'},
        data: {'name': 'Rui'},
        dataType: 'json',
        success: function() {
          console.log('successfully written in database')
        },
        error: function() {
          console.log('failed!')
        } 
      });
      $('#popup').hide( )
    }

    function cancel() {
      console.log('Mistake detection!')
      $('#popup').hide( )
    }

    $(document).ready(function() {
      run()
    })

  </script>
</html>